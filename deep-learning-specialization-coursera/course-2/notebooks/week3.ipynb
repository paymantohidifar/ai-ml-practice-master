{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65f74773-cd4b-4cbc-b596-a5ad528ca62b",
   "metadata": {},
   "source": [
    "# Week 3: Hyperparameter Tuning, Batch Normalization and Programming Frameworks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51292129-b137-4590-9e72-4790ff04e42d",
   "metadata": {},
   "source": [
    "### Tuning Process\n",
    "\n",
    "Tuning hyperparameters is a crucial but often challenging part of deep learning. The goal is to efficiently converge on the best settings by systematically organizing the search process.\n",
    "\n",
    "#### 1. Hyperparameter Importance Hierarchy\n",
    "Not all hyperparameters are equally important. Prioritizing which ones to tune first makes the search process more efficient.\n",
    "\n",
    "* **Most Important (Tier 1):**\n",
    "    * **Learning Rate ($\\alpha$):** This is almost universally the single most critical hyperparameter.\n",
    "* **Second Importance (Tier 2):**\n",
    "    * **Momentum ($\\beta$):** The decay rate for momentum (e.g., $0.9$ is a common default).\n",
    "    * **Mini-batch Size:** Important for optimizing training efficiency.\n",
    "    * **Number of Hidden Units/Layer Size:** Affects model capacity.\n",
    "* **Third Importance (Tier 3):**\n",
    "    * **Number of Layers:** Affects model depth.\n",
    "    * **Learning Rate Decay:** How the learning rate changes over time.\n",
    "* **Least Important (Often Fixed):**\n",
    "    * **Adam Optimization Parameters ($\\beta_1$, $\\beta_2$, $\\epsilon$):** Standard defaults (e.g., $0.9$, $0.999$, and $10^{-8}$) are often used without further tuning.\n",
    "\n",
    "#### 2. Effective Hyperparameter Search Strategy\n",
    "\n",
    "##### Random Sampling Over Grid Search\n",
    "* **Avoid Grid Search:** In deep learning, systematically exploring hyperparameters in a grid (e.g., a $5 \\times 5$ grid) is inefficient.\n",
    "* **Use Random Sampling:** Choose hyperparameters randomly from the defined search range.\n",
    "* **Rationale:** It's often unknown which hyperparameters are most critical *in advance*. Random sampling ensures you test a much **richer set of distinct values** for the most important hyperparameters (like $\\alpha$), significantly increasing the chance of finding an optimal value.\n",
    "\n",
    "##### Coarse-to-Fine Sampling\n",
    "* **Coarse Search:** Start by randomly sampling a small set of points across the entire hyperparameter range.\n",
    "* **Fine Search (Zoom In):** Once the coarse search identifies a promising region (where the best-performing models cluster), **zoom into that smaller region** and sample more densely (again, randomly) to focus computational resources on finding the precise optimal value.\n",
    "\n",
    "**Key Takeaways:** To organize your search efficiently, **prioritize tuning the learning rate ($\\alpha$)** and use a strategy of **random sampling** combined with an **optional coarse-to-fine search**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8606a05-340a-43a8-9ccd-4b3ae56d7c0e",
   "metadata": {},
   "source": [
    "### Using an Appropriate Scale to pick Hyperparameters\n",
    "\n",
    "While **random sampling** is the recommended method for hyperparameter tuning, it is crucial to sample on the **appropriate scale**—often a logarithmic scale—rather than uniformly, to ensure an efficient and comprehensive search.\n",
    "\n",
    "#### 1. Linear Scale (When Appropriate)\n",
    "For hyperparameters where the search range is narrow and linear changes have similar impacts, uniform sampling is acceptable.\n",
    "* **Examples:**\n",
    "    * **Number of Hidden Units ($n^{[l]}$):** If searching between 50 and 100, sampling uniformly at random across this range is reasonable.\n",
    "    * **Number of Layers ($L$):** For small integer ranges (e.g., 2 to 4), uniform sampling or even grid search is fine.\n",
    "\n",
    "#### 2. Logarithmic Scale (For Wide Ranges)\n",
    "For hyperparameters spanning a wide range of values where small changes at the low end are much more significant than small changes at the high end, a **logarithmic scale** is essential.\n",
    "\n",
    "* **Example: Learning Rate ($\\alpha$)**\n",
    "    * **Search Range:** $0.0001$ to $1$ (four orders of magnitude).\n",
    "    * **Problem with Uniform Sampling:** Uniform sampling dedicates $90\\%$ of resources to the range $0.1$ to $1$, while the crucial range $0.0001$ to $0.1$ is barely explored.\n",
    "    * **Logarithmic Solution:** Sample uniformly in the exponent.\n",
    "        * Find the exponents: $a = \\log_{10}(0.0001) = -4$ and $b = \\log_{10}(1) = 0$.\n",
    "        * Sample a random exponent $r$ uniformly between $a$ and $b$ (e.g., $r \\in [-4, 0]$).\n",
    "        * Set the hyperparameter: $\\alpha = 10^r$. This ensures equal resources are spent exploring each order of magnitude (e.g., $0.0001$ to $0.001$, $0.001$ to $0.01$, etc.).\n",
    "\n",
    "#### 3. Logarithmic Scale (For $\\beta$ in Exponentially Weighted Averages)\n",
    "The decay rate $\\beta$ (used in Momentum or Adam) is sensitive to the log scale, especially when $\\beta$ is close to 1.\n",
    "\n",
    "* **Search Range:** $0.9$ to $0.999$.\n",
    "* **Best Practice:** Tune the related term $\\mathbf{1 - \\beta}$ on a logarithmic scale instead.\n",
    "* **Rationale:** The effective averaging window is $\\frac{1}{1-\\beta}$.\n",
    "    * $\\beta=0.9 \\implies 1-\\beta=0.1$ (averaging $\\approx 10$ values).\n",
    "    * $\\beta=0.999 \\implies 1-\\beta=0.001$ (averaging $\\approx 1000$ values).\n",
    "    * Small changes when $\\beta$ is near 1 (e.g., $0.999$ to $0.9995$) have a massive impact on the averaging window (1000 to 2000), justifying a denser search in that area.\n",
    "* **Implementation:**\n",
    "    * Set the range for $1-\\beta$: $0.001$ to $0.1$.\n",
    "    * Find the exponents: $a = \\log_{10}(0.001) = -3$ and $b = \\log_{10}(0.1) = -1$.\n",
    "    * Sample $r$ uniformly between $a$ and $b$ (i.e., $r \\in [-3, -1]$).\n",
    "    * Set the hyperparameter: $\\mathbf{\\beta = 1 - 10^r}$.\n",
    "\n",
    "#### 4. General Conclusion\n",
    "Choosing the right scale for sampling (primarily logarithmic for wide or highly sensitive parameters) ensures resources are efficiently distributed, leading to a much faster convergence on optimal hyperparameter settings. This is a critical refinement to the random sampling strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da010788-17f0-4738-a4a6-e1fa1b783058",
   "metadata": {},
   "source": [
    "### Hyperparameters Turning in Practice\n",
    "\n",
    "#### 1. General Principles\n",
    "* **Intuitions Get Stale:** The best hyperparameter settings can become suboptimal over time due to gradual changes in data, server upgrades, or continued algorithm development.\n",
    "* **Recommendation:** Re-evaluate and **retest hyperparameters** at least once every several months to ensure the model maintains optimal performance.\n",
    "* **Cross-Fertilization:** Ideas and architectures from one application domain (e.g., computer vision) can often be successfully applied to others (e.g., speech or NLP).\n",
    "\n",
    "#### 2. Hyperparameter Search Approaches\n",
    "The choice of search strategy depends heavily on the available computational capacity:\n",
    "\n",
    "##### A. Babysitting One Model (Sequential Approach)\n",
    "* **Scenario:** Used when you have **limited computational resources** (few CPUs/GPUs) but a potentially huge dataset, allowing you to train only one or a very small number of models at a time.\n",
    "* **Process:** Start training a single model, and **manually monitor its learning curve** over the course of days or weeks. Based on the daily performance, you **gradually nudge** the learning rate or other parameters up or down.\n",
    "* **Goal:** Invest a lot of effort into making that single, complex model work.\n",
    "\n",
    "##### B. Training Many Models in Parallel\n",
    "* **Scenario:** Used when you have **sufficient computational resources** to train many models simultaneously.\n",
    "* **Process:** Initialize multiple models, each with a **different, randomly selected set of hyperparameters**. Let them all run for a fixed period (a day or more) without intervention.\n",
    "* **Goal:** Quickly compare the resulting learning curves and **pick the one that performs best** on the desired metric.\n",
    "\n",
    "#### 3. Next Step in Optimization\n",
    "The discussion leads to a powerful technique that can make neural networks much **more robust** to the choice of hyperparameters and accelerate training, which will be covered in the subsequent section."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77592b4a-3411-440a-b8fe-cfaa64d0a179",
   "metadata": {},
   "source": [
    "### Normalizing Activations in a Network\n",
    "\n",
    "Batch normalization (Batch Norm), proposed by Sergey Ioffe and Christian Szegedy, is a key deep learning technique that significantly **eases hyperparameter tuning**, makes neural networks more robust, and enables the easier training of very deep models.\n",
    "\n",
    "#### 1. The Core Idea: Extending Input Normalization\n",
    "* **Input Normalization:** Just as normalizing input features ($\\mathbf{X}$) speeds up training for models like logistic regression (by making the loss contours rounder), Batch Norm applies this idea to the hidden layers.\n",
    "* **Goal:** Normalize the activations in a hidden layer so that the next layer ($\\mathbf{W}^{[l+1]}, \\mathbf{b}^{[l+1]}$) trains more efficiently.\n",
    "\n",
    "#### 2. What Batch Norm Normalizes\n",
    "* **Preference:** While normalization could technically be applied to the activation ($\\mathbf{a}^{[l]}$), in practice, it is **most often applied to the pre-activation value ($\\mathbf{z}^{[l]}$)**.\n",
    "\n",
    "#### 3. The Batch Norm Algorithm (for a single layer)\n",
    "\n",
    "Given a set of pre-activation values $\\mathbf{z}_i$ for a specific layer across the mini-batch:\n",
    "\n",
    "1.  **Calculate Mean ($\\mu$):** Compute the mean of the $\\mathbf{z}_i$ values across the current mini-batch.\n",
    "    $$\\mu = \\frac{1}{m} \\sum_{i=1}^{m} \\mathbf{z}_i$$\n",
    "2.  **Calculate Variance ($\\sigma^2$):** Compute the variance of the $\\mathbf{z}_i$ values across the current mini-batch.\n",
    "    $$\\sigma^2 = \\frac{1}{m} \\sum_{i=1}^{m} (\\mathbf{z}_i - \\mu)^2$$\n",
    "3.  **Normalize ($\\mathbf{z}_{\\text{norm}}$):** Normalize the $\\mathbf{z}_i$ values to have a mean of 0 and a variance of 1.\n",
    "    $$\\mathbf{z}_{\\text{norm}, i} = \\frac{\\mathbf{z}_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}}$$ (where $\\epsilon$ is a small value for numerical stability).\n",
    "4.  **Rescale and Shift ($\\mathbf{\\tilde{z}}$):** Introduce two new **learnable parameters ($\\gamma$ and $\\beta$)** to control the final mean and variance.\n",
    "    $$\\mathbf{\\tilde{z}}_i = \\gamma \\mathbf{z}_{\\text{norm}, i} + \\beta$$\n",
    "    * **$\\gamma$ and $\\beta$ are learned:** They are updated via gradient descent just like the weights ($\\mathbf{W}$) and biases ($\\mathbf{b}$).\n",
    "    * **Flexibility:** If $\\gamma$ and $\\beta$ are set appropriately (e.g., $\\gamma = \\sqrt{\\sigma^2 + \\epsilon}$ and $\\beta = \\mu$), the Batch Norm transformation can compute the identity function ($\\mathbf{\\tilde{z}}_i = \\mathbf{z}_i$), allowing the network to fully control the distribution of $\\mathbf{z}$ beyond just mean 0 and variance 1.\n",
    "\n",
    "#### 4. Integration into the Network\n",
    "\n",
    "* **Substitution:** The normalized and scaled pre-activation value, $\\mathbf{\\tilde{z}}$, is used as the input to the activation function for that layer, replacing the original $\\mathbf{z}$.\n",
    "* **Benefit:** It ensures the hidden units have a controlled, standardized distribution (mean and variance are fixed and determined by the learned parameters $\\gamma$ and $\\beta$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068633f0-891e-4cd9-83b9-883d834b5ebb",
   "metadata": {},
   "source": [
    "### Fitting Batch Norm into a Neural Network\n",
    "\n",
    "This section explains the detailed placement and integration of **Batch Normalization (Batch Norm or BN)** within a deep neural network during the training process, particularly when using mini-batch gradient descent.\n",
    "\n",
    "#### 1. Placement of Batch Norm\n",
    "* Batch Norm is applied **between the linear calculation ($Z$) and the activation function ($A$)** in a given layer $L$.\n",
    "    * **Standard (No BN):** $A^{[L-1]} \\xrightarrow{W^{[L]}, b^{[L]}} Z^{[L]} \\xrightarrow{g} A^{[L]}$\n",
    "    * **With BN:** $A^{[L-1]} \\xrightarrow{W^{[L]}, b^{[L]}} Z^{[L]} \\xrightarrow{\\text{BN}} \\tilde{Z}^{[L]} \\xrightarrow{g} A^{[L]}$\n",
    "    * $\\tilde{Z}^{[L]}$ is the normalized, re-scaled value that is fed into the activation function $g$.\n",
    "\n",
    "#### 2. Batch Norm Parameters\n",
    "* BN introduces two new learnable parameters for **each layer $L$**:\n",
    "    * $\\boldsymbol{\\beta}^{[L]}$ (Beta): Controls the **shift** (mean) of the normalized output $\\tilde{Z}^{[L]}$.\n",
    "    * $\\boldsymbol{\\gamma}^{[L]}$ (Gamma): Controls the **scaling** (variance) of the normalized output $\\tilde{Z}^{[L]}$.\n",
    "* Both $\\boldsymbol{\\beta}^{[L]}$ and $\\boldsymbol{\\gamma}^{[L]}$ have the dimension of $(N_L, 1)$, where $N_L$ is the number of hidden units in layer $L$.\n",
    "* These parameters are learned during training using an optimization algorithm (like Gradient Descent, Adam, or RMSprop), similar to $W$.\n",
    "\n",
    "#### 3. Parameter Elimination ($B$ parameter)\n",
    "* If Batch Norm is used, the traditional bias parameter $B^{[L]}$ for that layer should be **eliminated (or set to zero)**.\n",
    "* **Reason:** The Batch Normalization step computes the mean of $Z^{[L]}$ and subtracts it. Since adding the constant $B^{[L]}$ to all examples in a mini-batch would just be canceled out by the mean subtraction, $B^{[L]}$ becomes redundant.\n",
    "* The role of shifting the mean is taken over by the learned parameter $\\boldsymbol{\\beta}^{[L]}$.\n",
    "    * **New Parameterization:** $Z^{[L]} = W^{[L]} A^{[L-1]}$ (no bias term).\n",
    "\n",
    "#### 4. Integration with Mini-Batch Gradient Descent\n",
    "* Batch Norm is typically applied using **mini-batches**.\n",
    "* **Normalization Scope:** For each mini-batch $X^{(t)}$, the BN operation computes the mean and variance of $Z^{[L]}$ **using only the data within that mini-batch** before normalizing $Z^{[L]}$ to $\\tilde{Z}^{[L]}$.\n",
    "* **Training Loop:**\n",
    "    1.  Iterate through mini-batches ($X^{(t)}$).\n",
    "    2.  Perform **Forward Propagation**: Compute $Z^{[L]}$, apply $\\text{BN}$ to get $\\tilde{Z}^{[L]}$, and then compute $A^{[L]}$.\n",
    "    3.  Perform **Backpropagation**: Compute gradients for $W$, $\\boldsymbol{\\beta}$, and $\\boldsymbol{\\gamma}$ (the $B$ gradient is ignored).\n",
    "    4.  **Update Parameters**: Use the chosen optimization algorithm (GD, Momentum, Adam, etc.) to update $W$, $\\boldsymbol{\\beta}$, and $\\boldsymbol{\\gamma}$.\n",
    "\n",
    "#### 5. Practical Implementation\n",
    "* In modern Deep Learning frameworks (like TensorFlow), the entire Batch Normalization layer logic (mean/variance calculation, normalization, and parameter updates) is usually implemented with a single **one-line function call** (`tf.nn.batch-normalization`).\n",
    "* Understanding the underlying mechanics, however, is key to debugging and effective use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20048c51-468d-446b-8794-7731ad265b00",
   "metadata": {},
   "source": [
    "### Why does Batch Norm Work?\n",
    "\n",
    "This section explains the primary reasons why **Batch Normalization (Batch Norm or BN)** is effective, focusing on **covariate shift reduction** and a minor **regularization effect**.\n",
    "\n",
    "#### 1. Accelerates Learning (Initial Intuition)\n",
    "* **Normalization:** Batch Norm normalizes the hidden unit values ($\\tilde{Z}^{[L]}$) in a deep network, similar to how normalizing input features ($X$) to mean zero and variance one speeds up convergence.\n",
    "* **Result:** This ensures all hidden units across different layers operate within a similar, stable range of values.\n",
    "\n",
    "#### 2. Reduces Covariate Shift in Hidden Layers (Primary Benefit)\n",
    "This is the main reason Batch Norm works so well.\n",
    "\n",
    "* **Covariate Shift Defined:** If a model is trained on a dataset where the input distribution changes, the model may perform poorly (e.g., training a cat detector only on black cats and applying it to colored cats). This distributional change is called **covariate shift**.\n",
    "* **Problem in Deep Networks:** As a neural network trains, the parameters ($W, B$) in the **early layers** are constantly changing. From the perspective of a **later layer** (e.g., Layer 3), the input values it receives ($A^{[2]}$ or $Z^{[2]}$) are constantly shifting their distribution due to those early layer updates. The later layer suffers from covariate shift.\n",
    "* **Batch Norm's Role:** BN ensures that even as the early layer parameters change, the mean and variance of the hidden unit values ($\\tilde{Z}^{[L]}$) seen by the next layer remain constant (constrained by the learned $\\beta$ and $\\gamma$).\n",
    "* **Result:** BN makes the input distribution to later layers **more stable**. This weakens the dependency (\"coupling\") between layers, allowing each layer to learn more independently and making the entire network converge faster.\n",
    "\n",
    "#### 3. Provides a Slight Regularization Effect\n",
    "* **Noisy Estimates:** During training, Batch Norm calculates the mean and variance for normalization using only the current **mini-batch**, not the entire dataset.\n",
    "* **Source of Noise:** Since the mean and variance are estimated from a relatively small sample (e.g., 64 examples), these estimates are slightly **noisy**.\n",
    "* **Effect:** This slight noise is applied during the scaling and shifting process (from $Z^{[L]}$ to $\\tilde{Z}^{[L]}$), similar to how **Dropout** adds noise to hidden activations.\n",
    "* **Result:** This forces downstream units not to rely too heavily on any single hidden unit's activation, providing a minor **regularization effect**.\n",
    "* **Note:** This effect is usually small. BN should be used primarily for accelerating learning, not as a primary regularizer, though it can be combined with Dropout for stronger regularization.\n",
    "* **Mini-Batch Size Impact:** Using a **larger mini-batch size** reduces the noise in the mean/variance estimates, thereby **reducing the regularization effect**.\n",
    "\n",
    "#### Next Step: Test-Time Operation\n",
    "* Since Batch Norm computes mean and variance per mini-batch during training, a different procedure is needed at **test time** when evaluating a single example, which will be covered next."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d25a488-0d39-495a-a402-afd7c74107d1",
   "metadata": {},
   "source": [
    "### Batch Norm at Test Time\n",
    "\n",
    "This section details the necessary adaptation of **Batch Normalization (BN)** for use at **test time** (or inference time), when examples are often processed individually rather than in mini-batches.\n",
    "\n",
    "#### 1. The Core Problem\n",
    "* **Training:** During training, $\\mu$ (mean) and $\\sigma^2$ (variance) are computed over the **current mini-batch** (e.g., 64 to 256 examples) and are used for normalization.\n",
    "* **Test Time:** At test time, you may only have a **single example** to process, and calculating the mean and variance for a single example is statistically meaningless.\n",
    "\n",
    "#### 2. The Solution: Estimating Global $\\mu$ and $\\sigma^2$\n",
    "To perform the necessary scaling at inference time, a separate estimate of the population mean ($\\mu$) and variance ($\\sigma^2$) for the $Z^{[L]}$ values of each layer must be established during training.\n",
    "\n",
    "* **Method:** In typical implementations, this is done by using an **Exponentially Weighted Average (EWA)** (also called a **running average**) of the $\\mu$ and $\\sigma^2$ values calculated for each mini-batch during the training process.\n",
    "* **Tracking:** The network keeps a running average of the $\\mu^{[L]}$ and $\\sigma^{2 [L]}$ encountered across all mini-batches for every layer $L$.\n",
    "\n",
    "#### 3. Test Time Application\n",
    "* **Inference:** When a single test example is input, the normalization steps are performed using the **stored EWA values** for $\\mu$ and $\\sigma^2$ instead of recalculating them.\n",
    "\n",
    "$$\\text{Z}_{\\text{norm}} = \\frac{Z - \\mu_{\\text{EWA}}}{\\sqrt{\\sigma^2_{\\text{EWA}} + \\epsilon}}$$\n",
    "\n",
    "* **Final Output:** The normalized $\\text{Z}_{\\text{norm}}$ is then rescaled using the learned $\\boldsymbol{\\gamma}$ and $\\boldsymbol{\\beta}$ parameters (which are saved from the training process) to produce $\\tilde{Z}$.\n",
    "* **Robustness:** The process is robust to the exact method used for estimating $\\mu$ and $\\sigma^2$. Deep learning frameworks typically handle this estimation by default, using EWA to get a reliable global average of the hidden unit statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675d5c29-ee1d-4554-9930-ad5eb12f73db",
   "metadata": {},
   "source": [
    "### Softmax Regression\n",
    "\n",
    "This section introduces **Softmax Regression** as a generalization of Logistic Regression for **multi-class classification** problems, detailing the mechanics of the Softmax activation function.\n",
    "\n",
    "#### 1. Purpose: Multi-Class Classification\n",
    "* **Definition:** Softmax Regression allows a neural network to make predictions where the output must belong to one of $C$ possible classes (where $C \\ge 3$).\n",
    "* **Class Indexing:** The number of classes is denoted by $C$. Classes are typically indexed from $0$ to $C-1$.\n",
    "* **Example:** Distinguishing between Cat (Class 1), Dog (Class 2), Baby Chick (Class 3), and None of the Above (Class 0). In this case, $C=4$.\n",
    "\n",
    "#### 2. Output Layer Structure\n",
    "* **Units:** The final layer ($L$) must have $C$ output units.\n",
    "* **Output ($\\hat{y}$ or $A^{[L]}$):** The output is a $C \\times 1$ vector where each element represents the **estimated probability** that the input $x$ belongs to a specific class.\n",
    "* **Constraint:** The $C$ probabilities in the output vector must **sum to 1**.\n",
    "\n",
    "#### 3. The Softmax Activation Function\n",
    "The Softmax function $g$ transforms the final layer's linear computation $Z^{[L]}$ into the final probability vector $A^{[L]}$. Unlike ReLU or Sigmoid, Softmax takes a vector input and produces a vector output.\n",
    "\n",
    "* **Linear Calculation:** $Z^{[L]} = W^{[L]} A^{[L-1]} + B^{[L]}$\n",
    "* **Transformation Steps (from $Z^{[L]}$ to $A^{[L]}$):**\n",
    "    1.  **Exponentiation:** Compute a temporary vector $T$, where $T_i = e^{Z^{[L]}_i}$ (element-wise exponentiation). This step ensures all components are positive.\n",
    "    2.  **Normalization:** Compute $A^{[L]}$ by dividing each element of $T$ by the sum of all elements in $T$.\n",
    "    $$\\text{For element } i: A^{[L]}_i = \\frac{e^{Z^{[L]}_i}}{\\sum_{j=0}^{C-1} e^{Z^{[L]}_j}}$$\n",
    "\n",
    "#### 4. Geometric Interpretation\n",
    "* **Decision Boundary:** Softmax regression with no hidden layers (like a generalized Logistic Regression) represents **multiple linear decision boundaries** separating the input space into $C$ distinct regions.\n",
    "* **Deeper Networks:** When used as the output layer of a deep neural network, Softmax allows the network to learn **complex, non-linear decision boundaries** to separate multiple classes effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108c6413-5aeb-4cae-83e5-4329a0710b0a",
   "metadata": {},
   "source": [
    "### Training a Softmax Classifier\n",
    "\n",
    "This section deepens the understanding of **Softmax Classification** as a generalization of Logistic Regression and details the loss function and key backpropagation step required for training a neural network that uses a Softmax output layer.\n",
    "\n",
    "#### 1. Softmax vs. Hardmax\n",
    "* **Softmax:** A \"gentle\" mapping that takes the linear output vector $Z^{[L]}$ and converts it into a vector of **probabilities** $A^{[L]}$ that **sum to 1**. It is calculated by exponentiating $Z$ and normalizing.\n",
    "* **Hardmax:** A conceptual function that takes $Z$ and outputs a vector with a **1** in the position of the largest element and $\\mathbf{0}$ everywhere else.\n",
    "\n",
    "#### 2. Generalization of Logistic Regression\n",
    "* Softmax Regression is a **generalization of Logistic Regression** to $C > 2$ classes.\n",
    "* If the number of classes $C=2$, the Softmax activation effectively reduces to the Logistic (Sigmoid) activation function. The two output probabilities are redundant since they must sum to 1.\n",
    "\n",
    "#### 3. The Loss Function (Cross-Entropy Loss)\n",
    "* The standard loss function used for Softmax classification is the **Cross-Entropy Loss**.\n",
    "* **Formula (Single Example):**\n",
    "    $$L(\\hat{y}, y) = -\\sum_{j=0}^{C-1} y_j \\log \\hat{y}_j$$\n",
    "* **Interpretation:** Since the true label $y$ is a one-hot vector (only the correct class $k$ is 1), the sum simplifies to:\n",
    "    $$L(\\hat{y}, y) = -y_k \\log \\hat{y}_k = -\\log \\hat{y}_k$$\n",
    "    The learning algorithm's goal is to **minimize this loss**, which is achieved by maximizing the predicted probability ($\\hat{y}_k$) for the ground truth class.\n",
    "* **Cost Function ($J$):** The overall cost is the average loss across all $M$ training examples:\n",
    "    $$J = \\frac{1}{M} \\sum_{i=1}^{M} L(\\hat{y}^{(i)}, y^{(i)})$$\n",
    "\n",
    "#### 4. Backpropagation Key Step\n",
    "* To start the backpropagation process and minimize the cost $J$, the derivative of the loss with respect to the final linear output $Z^{[L]}$ is required.\n",
    "* **Key Equation for $\\text{d}Z^{[L]}$:**\n",
    "    $$\\text{d}Z^{[L]} = \\hat{y} - y$$\n",
    "    (Where $\\hat{y}$ and $y$ are the $C \\times 1$ vectors for the predicted and true labels, respectively.)\n",
    "* **Practical Implementation:** While this equation is key for implementing Softmax from scratch, most **deep learning frameworks** (which will be used in practice) automatically handle the backpropagation step once the forward propagation and loss function are correctly specified."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a740f44-5ce1-4616-b039-3c438507f92e",
   "metadata": {},
   "source": [
    "### Deep learning Frameworks\n",
    "\n",
    "This section discusses the transition from implementing deep learning algorithms from scratch (e.g., using Python/NumPy) to utilizing specialized **Deep Learning Frameworks**, and provides criteria for choosing among them.\n",
    "\n",
    "#### 1. Shift to Frameworks (The Analogy)\n",
    "* **Initial Learning:** Implementing algorithms from scratch (e.g., in NumPy) is valuable for understanding the mechanics of deep learning.\n",
    "* **Practical Necessity:** For implementing **complex models** (like CNNs or RNNs) or **very large models**, implementing everything from scratch becomes impractical and inefficient for most people.\n",
    "* **Analogy:** Just as large-scale application development relies on calling optimized numerical linear algebra libraries for matrix multiplication (instead of coding it oneself), deep learning relies on specialized frameworks for efficiency.\n",
    "\n",
    "#### 2. Leading Frameworks and Credibility\n",
    "* **Current Landscape:** Today, many good deep learning software frameworks exist (e.g., TensorFlow, PyTorch, Caffe, MXNet, etc., though specific names aren't exhaustively listed).\n",
    "* **Viability:** Each leading framework has a dedicated user/developer community and is a **credible choice** for certain applications. Frameworks are evolving and improving rapidly.\n",
    "\n",
    "#### 3. Criteria for Choosing a Framework\n",
    "The choice of framework should be based on several practical and strategic factors:\n",
    "\n",
    "* **Ease of Programming:** This involves two aspects:\n",
    "    * **Development and Iteration:** How quickly and easily you can build and refine the neural network.\n",
    "    * **Deployment:** How easily the trained model can be integrated and used in production by millions of users.\n",
    "* **Running Speed:** The efficiency of the framework, especially when **training on large datasets**. Some frameworks offer better performance than others.\n",
    "* **Openness and Governance (Crucial Long-Term Factor):**\n",
    "    * The framework must be **open source**.\n",
    "    * It should have **good governance** to ensure it remains open and is not solely under the control of a single corporation that might eventually restrict or \"close off\" functionality.\n",
    "\n",
    "#### 4. Other Factors\n",
    "* **Language Preference:** Choose a framework that supports your preferred programming language (Python, C++, Java, etc.).\n",
    "* **Application Type:** The best choice may depend on the application domain (computer vision, NLP, online advertising, etc.).\n",
    "\n",
    "**Conclusion:** Deep learning frameworks provide a **higher level of abstraction** that makes developers much more efficient in building and deploying machine learning applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a6f4f-dab6-4ec7-810e-d84c8c40ae9e",
   "metadata": {},
   "source": [
    "### TensorFlow\n",
    "\n",
    "The section introduces the basic structure of a **TensorFlow** program, demonstrating how to define variables, compute a cost function, and use an optimizer to minimize that cost without manually implementing the derivative (backpropagation).\n",
    "\n",
    "#### 1. TensorFlow Setup and Variables\n",
    "* **Importing:** TensorFlow is conventionally imported as `import tensorflow as tf`.\n",
    "* **Parameter Definition:** Parameters (like the weight $W$) that the optimizer must update are defined using **`tf.Variable`**. These are the \"trainable variables.\"\n",
    "    * *Example:* `W = tf.Variable(0., dtype=tf.float32)`\n",
    "\n",
    "#### 2. Defining the Cost Function (Forward Prop)\n",
    "* **Core Principle:** The major advantage of TensorFlow is that the programmer only needs to write the code to compute the **cost function** (the **forward propagation** step).\n",
    "* **Cost Example:** A simple quadratic function $J(W) = W^2 - 10W + 25$ is used as a stand-in for a complex neural network cost.\n",
    "\n",
    "#### 3. Automatic Differentiation (Backprop)\n",
    "* **`tf.GradientTape`:** This is the mechanism TensorFlow uses to automatically compute gradients.\n",
    "    * **Function:** `tf.GradientTape` \"records\" the sequence of mathematical operations used to compute the cost function.\n",
    "    * **Backprop:** Once the cost is computed, the `tape.gradient()` function is called, which \"plays the tape backwards\" to automatically calculate the partial derivatives (gradients) of the cost with respect to the trainable variables.\n",
    "* **Computation Graph:** TensorFlow implicitly builds a **computation graph** from the defined forward propagation steps, allowing it to easily figure out all the necessary backward steps for backpropagation.\n",
    "\n",
    "#### 4. Optimization and Training Step\n",
    "* **Optimizer Definition:** An optimizer (e.g., Adam) is defined using `tf.keras.optimizers.Adam` with a specified learning rate.\n",
    "* **Applying Gradients (Manual Method):**\n",
    "    1.  Compute `grads = tape.gradient(cost, trainable_variables)`.\n",
    "    2.  Apply the update: `optimizer.apply_gradients(zip(grads, trainable_variables))`.\n",
    "* **Simpler Syntax (Alternative Method):**\n",
    "    * For a simple training step, the process can be condensed using: `optimizer.minimize(cost_function, var_list=[W])`.\n",
    "* **Efficiency:** The use of frameworks allows easy swapping of optimizers (e.g., Adam to RMSprop) by changing just one line of code.\n",
    "\n",
    "#### 5. Incorporating Data\n",
    "* **Data Input:** To make the cost function depend on training data (like $X$ or $Y$), the data can be represented as a TensorFlow array and included in the cost calculation. This demonstrates how to structure the program for neural networks where the cost depends on both parameters ($W$) and data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a4cfa0-989a-4077-807b-c8d64563c7d5",
   "metadata": {},
   "source": [
    "### Notes from Assignment notebook\n",
    "\n",
    "#### What does `dataset.prefetch()` do?\n",
    "\n",
    "The `dataset.prefetch()` transformation in TensorFlow is a critical performance optimization tool used to **overlap data preprocessing with model training**. It ensures that the CPU is preparing the next batch of data while the GPU (or other accelerator) is busy training the model on the current batch.\n",
    "\n",
    "#### How `prefetch()` Works\n",
    "\n",
    "##### 1. The Bottleneck Problem\n",
    "\n",
    "In a standard training pipeline without prefetching, the GPU often has to wait for the CPU to load and preprocess the next batch of data. This idle time for the GPU creates a bottleneck, slowing down overall training.\n",
    "\n",
    "##### 2. The Solution: Overlapping\n",
    "\n",
    "`prefetch()` inserts a **buffer** between the data producer (the input pipeline) and the data consumer (the model).\n",
    "\n",
    "  * While the accelerator (GPU/TPU) is executing the **training step** for batch $N$, the input pipeline (CPU) is asynchronously fetching and preprocessing **batch $N+1$**.\n",
    "  * When the accelerator finishes its work on batch $N$, batch $N+1$ is immediately ready in memory, minimizing idle time.\n",
    "\n",
    "##### 3. Key Argument: `buffer_size`\n",
    "\n",
    "The `prefetch()` function takes one important argument:\n",
    "\n",
    "  * **`buffer_size`**: This specifies the maximum number of elements (usually batches) that will be buffered.\n",
    "      * **Recommended Value:** `tf.data.AUTOTUNE`. This setting allows TensorFlow to dynamically tune the buffer size at runtime, maximizing the overlap between the producer and consumer stages.\n",
    "\n",
    "#### Code Example\n",
    "\n",
    "You typically place `prefetch()` as the **last step** in your input pipeline, after all mapping, shuffling, and batching operations.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "# Define the dataset pipeline\n",
    "dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "dataset = dataset.shuffle(buffer_size=1000)\n",
    "dataset = dataset.map(preprocess_fn) # CPU-intensive preprocessing\n",
    "dataset = dataset.batch(batch_size=32)\n",
    "\n",
    "# Prefetch is the final, crucial step for performance\n",
    "dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "# Model.fit will now consume data without waiting as much\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### What is TPU?\n",
    "A **TPU** is a **Tensor Processing Unit**, a custom-designed Application-Specific Integrated Circuit (ASIC) developed by Google specifically to accelerate machine learning workloads using TensorFlow (and other frameworks).\n",
    "\n",
    "#### Key Features and Purpose\n",
    "\n",
    "TPUs are designed to handle the massive amounts of matrix multiplication and addition operations that are at the core of neural network training and inference.\n",
    "\n",
    "* **Acceleration:** TPUs offer dramatically higher performance and energy efficiency than traditional CPUs and even standard GPUs for certain deep learning tasks.\n",
    "* **Precision:** They are optimized for lower-precision calculations (like `bfloat16`), which is sufficient for deep learning and allows for much faster computations.\n",
    "* **Scale:** TPUs are often deployed in large clusters, called **TPU Pods**, allowing researchers to train models that would otherwise take months on conventional hardware in a matter of hours or days.\n",
    "* **Architecture:** Unlike general-purpose CPUs and GPUs, TPUs have specialized architectures—including a large **Matrix Multiplier Unit (MXU)**—that are hardwired to execute tensor operations with extreme parallelism.\n",
    "\n",
    "TPUs are generally accessed by researchers and developers through cloud services, such as **Google Cloud TPU**, or directly through platforms like Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19245a41-89ea-44cb-bd99-727ef8934c35",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0aa37a-7916-480e-a98a-51bbe826f934",
   "metadata": {},
   "source": [
    "### HDF5 files\n",
    "\n",
    "HDF5, which stands for **Hierarchical Data Format, Version 5**, is a file format, data model, and library designed for storing and organizing **large, complex, and heterogeneous data**.\n",
    "\n",
    "It's widely used in scientific computing, engineering, machine learning, and data-intensive applications because of its structure and capabilities.\n",
    "\n",
    "#### Key Features of HDF5\n",
    "\n",
    "#### 1. Hierarchical Structure\n",
    "The \"Hierarchical\" part of the name is key. An HDF5 file can be thought of as a **self-contained file system** or a directory tree.\n",
    "\n",
    "* **Groups:** These act like **folders** or directories, organizing the data objects. Every file has a root group that can contain other groups.\n",
    "* **Datasets:** These are the actual **data objects**, representing typed, multidimensional arrays (like NumPy arrays in Python). They hold the raw data values.\n",
    "\n",
    "This structure allows you to organize data in a logical, file-system-like manner, making it easier to manage complex relationships.\n",
    "\n",
    "#### 2. Efficiency and Scalability\n",
    "HDF5 is built to handle **\"big data\"** efficiently:\n",
    "\n",
    "* **Selective Access (Slicing):** You can read and write only a **subset** or slice of a dataset without having to load the entire file into memory (RAM). This is crucial when working with terabyte-sized files.\n",
    "* **Compression:** Data files can be internally compressed using different schemes, reducing file size and improving storage and usage efficiency.\n",
    "\n",
    "#### 3. Self-Describing and Portable\n",
    "* **Self-Describing:** All elements (the file, groups, and datasets) can have associated **metadata** (called attributes) embedded within the file. This means an application can interpret the structure and contents of the file without requiring external information.\n",
    "* **Platform Portability:** HDF5 files are designed to be **platform-independent**, meaning data created on one operating system or machine architecture can be read reliably on another.\n",
    "\n",
    "#### 4. Machine Learning Application\n",
    "In deep learning and machine learning, HDF5 is often used to:\n",
    "* **Store Model Weights:** It is a common format for saving the weights and biases of a trained neural network model.\n",
    "* **Manage Large Datasets:** It efficiently handles large, structured datasets for model training, especially when data cannot fit entirely in memory.\n",
    "\n",
    "#### 5. Interaction\n",
    "HDF5 is accessed through software libraries and APIs, with popular interfaces available for languages like **Python** (via the `h5py` package, which integrates seamlessly with NumPy), C, C++, and MATLAB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4242056-1718-4f10-93f6-1425b7ebcdb7",
   "metadata": {},
   "source": [
    "### `iter()` function\n",
    "\n",
    "The Python built-in function **`iter()`** is used to get an **iterator** from an iterable object. It is a fundamental function that supports iteration (such as in `for` loops) throughout Python.\n",
    "\n",
    "The core benefit of using the built-in Python function **`iter()`** is that it is the foundational mechanism that enables efficient, memory-friendly, and standardized **iteration** across all data structures in Python.\n",
    "\n",
    "#### Key Concepts\n",
    "\n",
    "#### 1. The Purpose of `iter()`\n",
    "\n",
    "The primary purpose of `iter()` is to take an **iterable** object (like a list, tuple, string, or dictionary) and return a special object called an **iterator**.\n",
    "\n",
    "  * **Iterable:** An object you can loop over (i.e., it can return its elements one by one). It has an `__iter__` method.\n",
    "  * **Iterator:** An object that represents a stream of data. It must have a special method called **`__next__`** which, when called, returns the next item in the stream. When there are no more items, it raises a `StopIteration` exception.\n",
    "\n",
    "#### 2. How `iter()` Works\n",
    "\n",
    "When you call `iter(obj)`, it internally calls the object's `obj.__iter__()` method.\n",
    "\n",
    "| Input Object (`obj`) | Result of `iter(obj)` |\n",
    "| :--- | :--- |\n",
    "| **List, Tuple, String** | Returns a new **iterator object**. |\n",
    "| **Iterator Object** | Returns the **same iterator object** (or sometimes raises an error if the iterator doesn't implement `__iter__`). |\n",
    "\n",
    "#### 3. Relationship with `for` Loops\n",
    "\n",
    "You rarely call `iter()` explicitly, as it's automatically handled by Python's `for` loops:\n",
    "\n",
    "```python\n",
    "for item in my_list:\n",
    "    # Do something with item\n",
    "```\n",
    "\n",
    "This simple loop is conceptually translated by Python into steps that use `iter()` and the associated function, **`next()`**:\n",
    "\n",
    "1.  Python calls **`iterator = iter(my_list)`** to get an iterator.\n",
    "2.  In each loop iteration, Python calls **`item = next(iterator)`**.\n",
    "3.  When `next()` raises `StopIteration`, the loop automatically exits.\n",
    "\n",
    "-----\n",
    "\n",
    "#### Syntax and Overloading\n",
    "\n",
    "The `iter()` function has two forms:\n",
    "\n",
    "#### 1. Single-Argument Form (Most Common)\n",
    "\n",
    "  * **Syntax:** `iter(object)`\n",
    "  * **Usage:** Converts a standard iterable (list, string, etc.) into an iterator.\n",
    "\n",
    "#### 2. Two-Argument Form (Sentinel Value)\n",
    "\n",
    "  * **Syntax:** `iter(callable, sentinel)`\n",
    "  * **Usage:** Returns an iterator that repeatedly calls a function (`callable`) until the value it returns equals the `sentinel` value.\n",
    "  * **Example:** You can use this to read data from a file line by line until an empty string (`''`) is returned, or to read data from a socket until a specific \"end\" marker is hit.\n",
    "\n",
    "```python\n",
    "# Example: Create an iterator that calls a function until the result is 10\n",
    "i = 0\n",
    "def count_up():\n",
    "    global i\n",
    "    i += 1\n",
    "    return i\n",
    "\n",
    "# This iterator will stop when count_up() returns 10\n",
    "custom_iterator = iter(count_up, 10)\n",
    "\n",
    "# The loop will print 1 through 9\n",
    "# for val in custom_iterator:\n",
    "#     print(val)\n",
    "```\n",
    "\n",
    "#### Key Benefits of Using Iterators (via `iter()`)\n",
    "\n",
    "#### 1. Memory Efficiency (Lazy Evaluation)\n",
    "* **The Problem:** When dealing with massive datasets (e.g., millions of records or large files), creating a complete list of all items in memory (RAM) is often impossible or slow.\n",
    "* **The Solution:** Calling `iter()` on an iterable returns an **iterator** that performs **lazy evaluation**. This means the data is processed **one element at a time**, only when the `next()` function is called.\n",
    "* **Benefit:** This allows you to iterate over sequences of potentially **infinite size** or sequences that are too large to fit in memory, such as lines in a giant log file or a stream of data from a network socket.\n",
    "\n",
    "#### 2. Standardization of Iteration\n",
    "* **Uniform Access:** By returning an iterator, the `iter()` function provides a single, **unified interface** (the `__next__` method) for traversing *any* Python iterable, whether it's a list, a dictionary, a custom class, or a generator.\n",
    "* **Simplicity for Loops:** This standardization is why Python's **`for` loop** works seamlessly on lists, tuples, and custom classes—the loop's control flow implicitly calls `iter()` and then `next()`.\n",
    "\n",
    "#### 3. Iterators are Exhaustible (Control)\n",
    "* An iterator, once created by `iter()`, maintains its internal state. It keeps track of where it is in the sequence.\n",
    "* Once an iterator has yielded all of its values (and is \"exhausted\" by raising `StopIteration`), it cannot be reused.\n",
    "* **Benefit:** This provides predictable control flow, ensuring you process each element exactly once and making the loop logic simpler and safer. If you need to iterate again, you simply call `iter()` again on the original iterable to get a fresh iterator.\n",
    "\n",
    "#### 4. Implementing Custom Iterables\n",
    "* For advanced Python programmers, the existence of `iter()` and the iterator protocol (`__iter__` and `__next__`) allows them to create **custom classes** that behave exactly like built-in lists or tuples when used in a `for` loop or comprehension."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
