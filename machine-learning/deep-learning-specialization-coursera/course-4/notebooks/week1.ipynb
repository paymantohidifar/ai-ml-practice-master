{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f162c9e2",
   "metadata": {},
   "source": [
    "# Week 1: Foundations of Conventional Neural Netweorks\n",
    "\n",
    "Implement the foundational layers of CNNs (pooling, convolutions) and stack them properly in a deep network to solve multi-class image classification problems.\n",
    "\n",
    "**Learning Objectives**:\n",
    "\n",
    "* Explain the convolution operation\n",
    "* Apply two different types of pooling operations\n",
    "* Identify the components used in a convolutional neural network (padding, stride, filter, ...) and their purpose\n",
    "* Build a convolutional neural network\n",
    "* Implement convolutional and pooling layers in numpy, including forward propagation\n",
    "* Implement helper functions to use when implementing a TensorFlow model\n",
    "* Create a mood classifer using the TF Keras Sequential API\n",
    "* Build a ConvNet to identify sign language digits using the TF Keras Functional API\n",
    "* Build and train a ConvNet in TensorFlow for a binary classification problem\n",
    "* Build and train a ConvNet in TensorFlow for a multiclass classification problem\n",
    "* Explain different use cases for the Sequential and Functional APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da84dfc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d5600f",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c610b3d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0092d2f",
   "metadata": {},
   "source": [
    "## Computer Vision\n",
    "\n",
    "In this introduction to Convolutional Neural Networks (CNNs), the focus is on the transformative power of computer vision and the technical necessity of convolutions when dealing with high-resolution image data.\n",
    "\n",
    "### Importance and Impact of Computer Vision\n",
    "\n",
    "* **Rapid Advancement:** Deep learning has propelled computer vision into real-world utility, enabling self-driving cars, advanced face recognition, and relevant content curation in consumer apps.\n",
    "* **Cross-Fertilization:** Architectural innovations in computer vision often inspire breakthroughs in other fields, such as speech recognition.\n",
    "\n",
    "### Key Computer Vision Problems\n",
    "\n",
    "* **Image Classification:** Determining whether an object (e.g., a cat) is present in an image.\n",
    "* **Object Detection:** Not only identifying objects but also determining their specific positions and drawing bounding boxes around them.\n",
    "* **Neural Style Transfer:** Repainting a content image in the artistic style of a reference image (e.g., turning a landscape photo into a \"Picasso\" style painting).\n",
    "\n",
    "<img src='images/cv.png' width=750px>\n",
    "\n",
    "### The Challenge of Input Scale\n",
    "\n",
    "* **Small Images:** A $64 \\times 64$ RGB image has 12,288 features ($64 \\times 64 \\times 3$), which is manageable for standard fully connected networks.\n",
    "* **Large Images:** A modest $1000 \\times 1000$ (1-megapixel) image results in 3,000,000 input features.\n",
    "* **Parameter Explosion:** * In a fully connected layer with just 1,000 hidden units, a 1-megapixel input would require a weight matrix with 3 billion parameters.\n",
    "* **Overfitting:** With billions of parameters, models are highly prone to overfitting without massive amounts of data.\n",
    "* **Resource Constraints:** The memory and computational power required to train such a network are generally infeasible for standard hardware.\n",
    "\n",
    "<img src='images/input_scale.png' width=750px>\n",
    "\n",
    "### The Solution: Convolutional Operations\n",
    "\n",
    "* To process high-resolution images efficiently without a parameter explosion, deep learning uses **Convolutional Neural Networks (CNNs)**.\n",
    "* **Convolutions:** This operation is the fundamental building block of CNNs, allowing the network to learn local patterns (like edges) while drastically reducing the number of parameters compared to fully connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f1f1d0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c8a309",
   "metadata": {},
   "source": [
    "## Edge Detection Example\n",
    "\n",
    "The convolution operation is a fundamental building block of Convolutional Neural Networks (CNNs). It allows a model to learn features—starting with simple edges and progressing to complex objects—by sliding a filter over an input image.\n",
    "\n",
    "### What is the Convolution Operation?\n",
    "\n",
    "In computer vision, convolution is used to detect specific features, such as vertical or horizontal lines.\n",
    "* **The Input:** A grayscale image is represented as a matrix of pixel intensities (e.g., a $6 \\times 6 \\times 1$ matrix).\n",
    "* **The Filter (or Kernel):** A smaller matrix (typically $3 \\times 3$) designed to identify a specific pattern. For a vertical edge detector, a common filter is:\n",
    "\n",
    "$$ \\begin{bmatrix} 1 & 0 & -1 \\\\ 1 & 0 & -1 \\\\ 1 & 0 & -1 \\end{bmatrix}$$\n",
    "\n",
    "* **The Notation:** In math and deep learning, the asterisk ($*$) denotes the convolution operation (not to be confused with standard multiplication).\n",
    "\n",
    "### The Mechanics of Convolution\n",
    "\n",
    "The process of convolving a $6 \\times 6$ image with a $3 \\times 3$ filter results in a $4 \\times 4$ output matrix.\n",
    "\n",
    "1. **Overlay:** Place the $3 \\times 3$ filter over the top-left $3 \\times 3$ patch of the image.\n",
    "2. **Element-wise Product:** Multiply each of the 9 numbers in the filter by the corresponding pixel value in the image patch.\n",
    "3. **Summation:** Add those 9 products together to get a single value for the first cell of the output matrix.\n",
    "4. **Shift (Slide):** Move the filter one pixel to the right (the \"stride\") and repeat the calculation. Once the row is finished, move down and start the next row.\n",
    "\n",
    "### Intuition: Why It Detects Edges\n",
    "\n",
    "The filter acts as a mathematical \"transition detector.\"\n",
    "* **Vertical Edge Case:** Imagine an image where the left half is bright (pixel value 10) and the right half is dark (pixel value 0).\n",
    "* **The Calculation:** When the filter (with 1s on the left and -1s on the right) sits on the transition:\n",
    "    * The 1s multiply the bright pixels (high positive sum).\n",
    "    * The -1s multiply the dark pixels (near-zero sum).\n",
    "* **The Result:** The sum is a large positive number (e.g., 30). In areas where the color is uniform (all 10s or all 0s), the 1s and -1s cancel each other out, resulting in 0.\n",
    "* **Visual Output:** The final $4 \\times 4$ matrix will show a bright \"strip\" in the middle, representing the detected edge.\n",
    "### Practical Implementation\n",
    "\n",
    "In deep learning frameworks, you don't perform these sums manually. Functions are built-in to handle high-dimensional convolutions:\n",
    "* **TensorFlow:** `tf.nn.conv2d`\n",
    "* **Keras:** `Conv2D layer`\n",
    "* **Output Dimensions:** For an $n \\times n$ image and an $f \\times f$ filter, the output size is generally $(n - f + 1) \\times (n - f + 1)$. In our example, $6 - 3 + 1 = 4$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
