{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d221adb0-3aa9-46f9-a083-ef7df01fbb7d",
   "metadata": {},
   "source": [
    "# Week 2: Recommender Systems\n",
    "\n",
    "### Table of Contents\n",
    "1. [Making Recommendations](#Making-Recommendations)\n",
    "2. [Using per-item features](#using-per-item-features)\n",
    "3. [Collaborative filtering algorithm](#collaborative-filtering-algorithm)\n",
    "4. [Binary labels: favs, likes and clicks](#binary-labels-favs-likes-and-clicks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cc2e0f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aad6020-87f3-4c9d-8e98-18d98708a993",
   "metadata": {},
   "source": [
    "## Making Recommendations\n",
    "\n",
    "This section introduces the topic of Recommender Systems, highlighting their significant commercial impact and setting up the basic framework and notation using the example of movie rating prediction.\n",
    "\n",
    "### Commercial Importance\n",
    "\n",
    "* **Widespread Use:** Recommender systems are used everywhere online (e.g., shopping sites like Amazon, streaming services like Netflix, food delivery apps).\n",
    "* **High Value:** For many companies, a large fraction of sales and economic value is directly driven by the success of their recommender systems.\n",
    "* **Academic vs. Commercial Attention:** The commercial impact of recommender systems is arguably vastly greater than the attention it receives in academia.\n",
    "\n",
    "### Core Framework (Movie Rating Example)\n",
    "The goal is to predict how users would rate movies they haven't yet watched (denoted by '?') to decide what to recommend.\n",
    "\n",
    "| Item | Notation | Definition/Example |\n",
    "| :--- | :--- | :--- |\n",
    "| **Number of Users** | $n_u$ | In the example, $n_u = 4$ (Alice, Bob, Carol, Dave). |\n",
    "| **Number of Items (Movies)** | $n_m$ | In the example, $n_m = 5$. |\n",
    "| **Rating Indicator** | $r(i, j)$ | A binary value: $r(i, j) = 1$ if user $j$ has rated movie $i$; $0$ otherwise. |\n",
    "| **Actual Rating** | $y^{(i, j)}$ | The rating (0 to 5 stars) given by user $j$ to movie $i$. (E.g., $y^{(3, 2)} = 4$). |\n",
    "\n",
    "### Next Step\n",
    "The subsequent lesson will begin developing an algorithm to predict the missing ratings. The first model will temporarily assume that features (extra information) about the movies (e.g., whether it is a romance movie or an action movie) are already available. Later in the notes, we will address how to build the system when these explicit movie features are not available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27fe117-e203-4d24-951e-5556e3a65fd6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53dcb8a0-978b-4734-b356-2b2064f41b98",
   "metadata": {},
   "source": [
    "## Using per-item features\n",
    "\n",
    "This section details the first approach to building a recommender system: using **pre-existing item features** to create a personalized linear regression model for each user.\n",
    "\n",
    "### Framework and Notation\n",
    "\n",
    "We have pre-defined features ($X$) for each item (movie), such as $x_1$ (Romance level) and $x_2$ (Action level).\n",
    "* $n_u$: Number of users (e.g., 4).\n",
    "* $n_m$: Number of movies/items (e.g., 5).\n",
    "* $n$: Number of features (e.g., 2).\n",
    "* $r(i, j) = 1$: User $j$ has rated movie $i$.\n",
    "* $y^{(i, j)}$: The actual rating given by user $j$ to movie $i$.\n",
    "\n",
    "### The Model: Personalized Linear Regression\n",
    "\n",
    "The system fits a separate linear regression model for each user $j$ to predict their rating for any movie $i$.\n",
    "\n",
    "$$\\text{Prediction for } y^{(i, j)} = \\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)}$$\n",
    "* $\\mathbf{w}^{(j)}$ and $b^{(j)}$ are the unique parameters (weights and bias) learned for user $j$.\n",
    "* $\\mathbf{x}^{(i)}$ is the feature vector for movie $i$.\n",
    "\n",
    "### The Cost Function\n",
    "\n",
    "The objective is to learn the parameters ($\\mathbf{w}^{(j)}$ and $b^{(j)}$) for all users simultaneously by minimizing a regularized mean squared error cost function.\n",
    "\n",
    "* **Cost Function for All Users ($J$):** The cost is the sum of the individual cost functions for every user.\n",
    "    \n",
    "    $$J(\\mathbf{w}^{(1)}, b^{(1)}, \\dots, \\mathbf{w}^{(n_u)}, b^{(n_u)}) = \\sum_{j=1}^{n_u} J(\\mathbf{w}^{(j)}, b^{(j)})$$\n",
    "\n",
    "* **Individual User Cost ($J(\\mathbf{w}^{(j)}, b^{(j)})$):**\n",
    "    \n",
    "    $$J(\\mathbf{w}^{(j)}, b^{(j)}) = \\frac{1}{2} \\sum_{i: r(i, j)=1} \\left( (\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)}) - y^{(i, j)} \\right)^2 + \\frac{\\lambda}{2} \\sum_{k=1}^{n} (w_k^{(j)})^2$$\n",
    "\n",
    "    * The sum $\\sum_{i: r(i, j)=1}$ means we only calculate the error for movies that user $j$ has actually rated.\n",
    "    * The second term is standard regularization to prevent overfitting. (Note: The normalization constant $1/m^{(j)}$ is omitted for convenience, as it doesn't change the parameters at the minimum; <u>for detailed information see Bonus below)</u>.\n",
    "\n",
    "### Bonus: *Dropping the Normalization Constant in Recommender Systems*\n",
    "\n",
    "The term related to the number of movies rated by user $j$, $m^{(j)}$, is often dropped from the denominator of the Collaborative Filtering cost function because it is a constant scaling factor that does not affect the model's ultimate performance.\n",
    "\n",
    "#### 1. Scaling Does Not Change the Minimum\n",
    "\n",
    "* The overall goal is to find the parameters ($\\mathbf{w}^{(j)}$ and $b^{(j)}$) that minimize the cost function $J$.\n",
    "* $1/2m^{(j)}$ is a constant scaling factor determined by the training data.\n",
    "* Multiplying or dividing the entire cost function by a positive constant only scales it vertically; it does not change the location of the minimum point (the optimal parameters).\n",
    "    $$ \\text{arg min}_{\\mathbf{w}, b} \\left[ J_{\\text{original}}(\\mathbf{w}, b) \\right] = \\text{arg min}_{\\mathbf{w}, b} \\left[ \\mathbf{C} \\cdot J_{\\text{simplified}}(\\mathbf{w}, b) \\right] \\quad \\text{where } \\mathbf{C} = \\frac{1}{2m^{(j)}} \\text{ is the constant.}$$\n",
    "\n",
    "#### 2. Simplifies Optimization\n",
    "\n",
    "* In Gradient Descent, dropping the constant $\\frac{1}{2m^{(j)}}$ only scales the magnitude of the gradient. This is compensated for by adjusting the learning rate ($\\alpha$).\n",
    "* For Collaborative Filtering, the overall cost function $J_{\\text{overall}}$ is a sum of individual user costs $J(\\mathbf{w}^{(j)}, b^{(j)})$. Using different division factors ($m^{(j)}$) for every user's loss and regularization terms unnecessarily complicates the algebra for joint optimization.\n",
    "* Dropping the constant leads to a cleaner, unified cost function primarily focused on minimization.\n",
    "\n",
    "#### Comparison to Linear Regression (MSE)\n",
    "\n",
    "The normalization term ($1/m$) is typically retained in standard Linear Regression (Mean Squared Error, MSE) for statistical and practical reasons.\n",
    "\n",
    "| Context | Purpose of $J$ | Why $1/m$ is Kept/Dropped |\n",
    "| :--- | :--- | :--- |\n",
    "| Linear Regression | Evaluation and Comparison (MSE) | Kept, because it defines the average squared error (MSE), making the cost value interpretable and comparable across datasets of different sizes. |\n",
    "| Recommender System | Optimization | Dropped, because $m^{(j)}$ is a constant that doesn't change the optimal parameters and unnecessarily complicates the joint cost function. |\n",
    "\n",
    "### Next Challenge\n",
    "\n",
    "* The current method relies on having pre-defined features ($\\mathbf{x}^{(i)}$) for every item.\n",
    "* The next section will explore a modification of this algorithm—**Collaborative Filtering**—which works even when these detailed item features are not available beforehand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b379da-5907-4ff3-8e6d-965ff6c4a3ee",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22e82ca-5576-4228-b9dc-f89b10aed2aa",
   "metadata": {},
   "source": [
    "## Collaborative filtering algorithm\n",
    "\n",
    "This section introduces **Collaborative Filtering**, a powerful technique for recommender systems where the item features ($\\mathbf{x}$) are learned from the user ratings rather than being provided in advance.\n",
    "\n",
    "### 1. The Challenge: Learning Item Features ($\\mathbf{x}$)\n",
    "\n",
    "In the previous model, we assumed movie features ($\\mathbf{x}$) were known (e.g., Romance, Action level). In the new new approach, when features are unknown, the ratings provided by multiple users on the same item can be leveraged to learn what those item features ($\\mathbf{x}$) should be.\n",
    "\n",
    "**Why it Works:** Having ratings from several users (each with known preference parameters $\\mathbf{w}$ and $b$) allows the system to infer the features of an unfeatured movie that best explain those ratings. This relies on the \"collaboration\" of ratings from multiple users on the same item, which defines algorithm's name.\n",
    "\n",
    "### 2. Cost Function for Learning Features ($\\mathbf{x}$)\n",
    "\n",
    "If the user preference parameters ($\\mathbf{w}^{(j)}, b^{(j)}$) are temporarily fixed, the features for a single movie $i$ ($\\mathbf{x}^{(i)}$) are learned by minimizing the cost function:\n",
    "\n",
    "$$\\min_{\\mathbf{x}^{(i)}} J(\\mathbf{x}^{(i)}) = \\frac{1}{2} \\sum_{j: r(i, j)=1} \\left( (\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)}) - y^{(i, j)} \\right)^2 + \\frac{\\lambda}{2} \\sum_{k=1}^{n} (x_k^{(i)})^2$$\n",
    "\n",
    "### 3. The Full Collaborative Filtering Cost Function\n",
    "\n",
    "The final algorithm combines the objective of learning user preferences ($\\mathbf{w}, b$) and learning item features ($\\mathbf{x}$) into a single unified cost function ($J$):\n",
    "\n",
    "* **Minimization:** The algorithm simultaneously minimizes $J$ with respect to all parameters: the user parameters ($\\mathbf{w}^{(j)}, b^{(j)}$ for all users $j$) and the movie features ($\\mathbf{x}^{(i)}$ for all movies $i$).\n",
    "* **Unified Cost ($J$):** This combines the prediction error and the regularization terms for both users and movies.\n",
    "\n",
    "$$J(\\mathbf{w}, \\mathbf{b}, \\mathbf{x}) = \\frac{1}{2} \\sum_{(i, j): r(i, j)=1} \\left( (\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)}) - y^{(i, j)} \\right)^2 + \\frac{\\lambda}{2} \\sum_{j=1}^{n_u} \\sum_{k=1}^{n} (w_k^{(j)})^2 + \\frac{\\lambda}{2} \\sum_{i=1}^{n_m} \\sum_{k=1}^{n} (x_k^{(i)})^2$$\n",
    "\n",
    "### 4. Optimization\n",
    "\n",
    "Gradient Descent or other optimization algorithms are used to minimize the cost function $J$. In this full formulation, both the user preferences ($\\mathbf{w}, \\mathbf{b}$) and the item features ($\\mathbf{x}$) are treated as parameters to be learned and are updated iteratively.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "w_i^{(j)} &= w_i^{(j)} - \\alpha \\frac{\\partial}{\\partial w_i^{(j)}}J(w, b,x) \\\\\n",
    "b^{(j)} &= b^{(j)} - \\alpha \\frac{\\partial}{\\partial b^{(j)}}J(w, b,x) \\\\\n",
    "x_k^{(i)} &= x_k^{(i)} - \\alpha \\frac{\\partial}{\\partial x_k^{(i)}}J(w, b,x)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### Next Step\n",
    "The next section will address a generalization of this model to systems using binary labels (e.g., like/dislike) instead of continuous star ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf1b0f-e04f-4692-b82b-bd7012414b66",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac93af2-037c-497f-95bf-851c0662f6f9",
   "metadata": {},
   "source": [
    "## Binary labels: favs, likes and clicks\n",
    "\n",
    "This section explains how to adapt the collaborative filtering algorithm from predicting continuous ratings (like 1–5 stars) to predicting **binary labels** (like/dislike, purchase/not purchase), using a method analogous to moving from linear regression to logistic regression.\n",
    "\n",
    "### Binary Label Context\n",
    "\n",
    "Many recommender systems deal with binary labels (1 or 0) rather than star ratings.\n",
    "\n",
    "* **Label Meanings (Engagement):**\n",
    "    * **1 (Engaged):** User liked, purchased, favorited, clicked, or spent a minimum time (e.g., 30 seconds) on an item after exposure.\n",
    "    * **0 (Not Engaged):** User did not like, did not purchase, or left quickly after being exposed to the item.\n",
    "    * **? (Question Mark):** The user was not yet exposed to the item (no rating/engagement data).\n",
    "* **Goal:** Predict the probability that a user will like or engage with a new item (the '?' items) to decide what to recommend.\n",
    "\n",
    "### The Model: Logistic Regression Analogy\n",
    "\n",
    "The model shifts from predicting a numerical rating to predicting a probability of engagement. The linear combination of user preferences ($\\mathbf{w}^{(j)}$) and item features ($\\mathbf{x}^{(i)}$) is passed through the logistic function ($g$) (also known as the sigmoid function).\n",
    "\n",
    "$$\\text{P}(y^{(i, j)}=1) = g(\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)})$$\n",
    "\n",
    "where $g(z) = \\frac{1}{1 + e^{-z}}$.\n",
    "\n",
    "### The Cost Function: Binary Cross-Entropy\n",
    "\n",
    "Since the output is a probability and the labels are binary, the squared error cost function (used for ratings) is replaced with the Binary Cross-Entropy Loss (or log loss), which is standard for logistic regression.\n",
    "\n",
    "* **Loss for a Single Example:**\n",
    "    $$L(f(\\mathbf{x}), y) = -y \\log(f(\\mathbf{x})) - (1-y) \\log(1-f(\\mathbf{x}))$$\n",
    "* **Overall Binary Collaborative Filtering Cost ($J$):** The total cost function sums this binary cross-entropy loss over all user-item pairs where a rating/engagement exists ($r^{(i, j)}=1$), plus the regularization terms for all $\\mathbf{w}$, $\\mathbf{b}$, and $\\mathbf{x}$.\n",
    "\n",
    "$$J(\\mathbf{w}, \\mathbf{b}, \\mathbf{x}) = \\sum_{(i, j): r(i, j)=1} L(f(x^{(i)}), y^{(i,j)}) + \\frac{\\lambda}{2} \\sum_{j=1}^{n_u} \\sum_{k=1}^{n} (w_k^{(j)})^2 + \\frac{\\lambda}{2} \\sum_{i=1}^{n_m} \\sum_{k=1}^{n} (x_k^{(i)})^2$$\n",
    "\n",
    "### Generalization\n",
    "\n",
    "This generalization significantly opens up the set of applications that can be addressed by collaborative filtering, allowing the algorithm to work with implicit feedback (like clicks or viewing time) rather than requiring explicit user ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b144d958-e503-4659-b428-1ddbd3b7aee4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a54aac6",
   "metadata": {},
   "source": [
    "## Mean Normalization\n",
    "\n",
    "Mean normalization is a technique used in recommender systems to preprocess movie ratings, making the learning algorithm run more efficiently and, more importantly, providing better initial predictions for new users who haven't rated any items.\n",
    "\n",
    "### Purpose of Mean Normalization\n",
    "\n",
    "* **Algorithm Efficiency:** Normalization can help the optimization algorithm (like gradient descent) run faster, similar to feature normalization in linear regression.\n",
    "* **Improved Predictions for New Users:** It prevents the algorithm from predicting a zero rating for all movies for a brand new user who has not yet provided any ratings.\n",
    "\n",
    "### The Problem Without Normalization\n",
    "\n",
    "* If a new user (like Eve) has rated no movies, the regularization term in the cost function will drive her preference parameters ($\\mathbf{w}^{(5)}$ and $b^{(5)}$) to be $\\mathbf{0}$.\n",
    "* The predicted rating for any movie $i$ would be $\\mathbf{w}^{(5)} \\cdot \\mathbf{x}^{(i)} + b^{(5)} = 0$, leading to the unhelpful prediction that the new user will rate all movies zero stars.\n",
    "\n",
    "### Mean Normalization Process\n",
    "\n",
    "* **Calculate Movie Means ($\\mu$):** For each movie $i$, compute the average rating $\\mu_i$ given by only the users who have rated that movie.\n",
    "* **Normalize Ratings ($Y$):** Create a new rating matrix where the average rating $\\mu_i$ is subtracted from every rating $y^{(i, j)}$ for movie $i$. This new matrix is used as the training target.\n",
    "    * Example: A 5-star rating for a movie with an average of 2.5 becomes $5 - 2.5 = 2.5$.\n",
    "\n",
    "<img src=\"images/mean_norm.png\" width=700>\n",
    "\n",
    "* **Impact on New Users:** With this normalization, the parameters for a new user like Eve will still be $\\mathbf{w}^{(5)}=\\mathbf{0}$ and $b^{(5)}=0$. However, these parameters now predict a **normalized rating of 0**.\n",
    "\n",
    "### Making Predictions with Normalization\n",
    "\n",
    "* To make a final, non-normalized rating prediction for user $j$ on movie $i$, the mean rating ($\\mu_i$) must be added back:\n",
    "$$\\text{Prediction} = (\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)}) + \\mu_i$$\n",
    "\n",
    "### Benefits for New Users\n",
    "\n",
    "* Because $\\mathbf{w}^{(5)} \\cdot \\mathbf{x}^{(i)} + b^{(5)} = 0$ for a new user, the predicted rating simplifies to $\\text{Prediction} = \\mu_i$.\n",
    "* This means the algorithm initially guesses that the new user will rate a movie equal to the **average rating** that other users gave that movie, which is a much more reasonable initial guess than zero stars.\n",
    "\n",
    "### Row vs. Column Normalization\n",
    "\n",
    "* **Row Normalization (Normalizing by Movie/Item):** This is the focus of the process described, which helps generate reasonable predictions for a **new user** who has few or no ratings.\n",
    "* **Column Normalization (Normalizing by User):** This would help if there was a brand **new movie** with no ratings. However, normalizing by movie (row normalization) is considered more important in this application because new users are often served content immediately, whereas new movies are usually held back until they receive some initial ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019d6e15",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb23d8e6",
   "metadata": {},
   "source": [
    "## TensorFlow implementation of collaborative filtering\n",
    "\n",
    "This section explains how to implement the collaborative filtering algorithm using **TensorFlow's Automatic Differentiation (Auto Diff)** feature, which simplifies optimization by removing the need for manual calculus.\n",
    "\n",
    "### TensorFlow for Non-Neural Networks\n",
    "\n",
    "* TensorFlow is not limited to neural networks; it is a versatile tool for implementing various learning algorithms, including collaborative filtering.\n",
    "* The primary advantage of using TensorFlow here is its Automatic Differentiation (Auto Diff) feature (sometimes incorrectly called Auto Grad).\n",
    "\n",
    "### Automatic Differentiation (Auto Diff)\n",
    "\n",
    "* **Goal:** To implement Gradient Descent (or other optimization algorithms such as Adam) without manually computing the partial derivatives of the cost function ($J$).\n",
    "* **Mechanism (Gradient Tape):** TensorFlow uses a feature called the **Gradient Tape** (`tf.GradientTape`).\n",
    "    1.  The user defines how to compute the cost function ($J$).\n",
    "    2.  The Gradient Tape records the sequence of operations (the forward pass) used to calculate $J$.\n",
    "    3.  TensorFlow then uses this recorded sequence to automatically compute the necessary derivatives (the backward pass).\n",
    "\n",
    "### Implementing Gradient Descent (Conceptual Example)\n",
    "\n",
    "The core steps in Python/TensorFlow syntax are:\n",
    "1.  **Initialize Parameters:** Define parameters (like $w, b, x$) as TensorFlow variables (`tf.Variable`).\n",
    "2.  **Use Gradient Tape:** Wrap the calculation of the cost function $J$ inside the `with tf.GradientTape as tape:` block.\n",
    "3.  **Compute Derivatives:** Use `tape.gradient(J, [parameters])` to get the derivatives (gradients) of $J$ with respect to the specified parameters.\n",
    "4.  **Update Parameters:** Use the gradients to update the parameters (e.g., $w = w - \\alpha \\cdot \\frac{\\partial J}{\\partial w}$).\n",
    "\n",
    "### Collaborative Filtering Implementation\n",
    "\n",
    "* **Algorithm Choice:** Using Auto Diff allows the use of more powerful algorithms than simple Gradient Descent, such as the Adam optimization algorithm.\n",
    "* **Cost Function:** The user must provide the code to compute the collaborative filtering cost function $J$ (which takes inputs like $\\mathbf{x}, \\mathbf{w}, \\mathbf{b}$, normalized ratings $Y_{\\text{norm}}$, and the regularization parameter $\\lambda$).\n",
    "* **Optimization Steps (Adam):**\n",
    "    1.  Define the Adam optimizer (`keras.optimizers.Adam`).\n",
    "    2.  Use the Gradient Tape to compute the cost $J$.\n",
    "    3.  Compute the derivatives (`grads`).\n",
    "    4.  Apply the gradients using the optimizer (`optimizer.apply_gradients`).\n",
    "\n",
    "### Why Not Use Standard Keras (`model.compile`, `model.fit`)?\n",
    "\n",
    "The collaborative filtering cost function does not neatly fit into the standard, pre-defined neural network layer types (like `Dense` layers) provided by Keras/TensorFlow. Therefore, the custom approach of defining the cost function and using Auto Diff is necessary, making it a very effective way to implement custom learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14c0a47",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a970b821",
   "metadata": {},
   "source": [
    "## Finding related items\n",
    "\n",
    "The collaborative filtering algorithm, which learns item features from user ratings, can be used to identify related items based on the similarity of their learned feature vectors. The algorithm, however, suffers from limitations such as the cold start problem and an inability to easily integrate external side information.\n",
    "\n",
    "The collaborative filtering algorithm automatically learns a feature vector $\\mathbf{x}^{(i)}$ for every item $i$. Although these features (e.g., $x_1, x_2$) are often difficult for a human to interpret (they don't neatly correspond to genres like \"action\" or \"romance\"), they collectively capture the essence of the item.\n",
    "\n",
    "To find items related to item $i$, the algorithm searches for other items $k$ whose feature vectors $\\mathbf{x}^{(k)}$ are mathematically close to $\\mathbf{x}^{(i)}$. The similarity (or dissimilarity) between two items' feature vectors is typically measured using the **squared distance** between them:\n",
    "\n",
    "$$\\text{Squared Distance} = \\sum_{l=1}^{n} (x_l^{(k)} - x_l^{(i)})^2$$\n",
    "\n",
    "By finding the items (movies, products, etc.) with the smallest squared distance, the system identifies and recommends the most similar items to the user.\n",
    "\n",
    "### Limitations of Collaborative Filtering\n",
    "\n",
    "The collaborative filtering algorithm has two primary weaknesses:\n",
    "\n",
    "#### 1. The Cold Start Problem\n",
    "\n",
    "The algorithm struggles when it lacks sufficient data for either a new item or a new user.\n",
    "* **New Items:** If a new movie or product is added to the catalog and few users have rated it yet, the algorithm cannot accurately determine its features $\\mathbf{x}^{(i)}$ or recommend it effectively.\n",
    "* **New Users:** Similarly, if a new user has rated only a few items, the system cannot accurately determine their preference parameters ($\\mathbf{w}^{(j)}, b^{(j)}$) to give personalized predictions (though mean normalization can help provide reasonable initial guesses based on overall average ratings).\n",
    "\n",
    "#### 2. Inability to Use Side Information\n",
    "\n",
    "Collaborative filtering does not provide a natural mechanism to incorporate external data (side information) that is known about items or users.\n",
    "* **Item Side Information:** This includes known facts about a movie like its genre, cast, director, budget, or studio.\n",
    "* **User Side Information:** This includes user demographics (age, gender, location), stated preferences, or even behavioral cues like their web browser or whether they are using a mobile or desktop device.\n",
    "\n",
    "Integrating this rich, external side information is necessary to improve accuracy and address the cold start problem more robustly.\n",
    "\n",
    "### Next\n",
    "The next step in recommender system development is **Content-Based Filtering**, which is designed to specifically address these limitations by leveraging side information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a34f4d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76541fc",
   "metadata": {},
   "source": [
    "\n",
    "## Vectorized Formulation for Collaborative Filtering in TensorFlow\n",
    "\n",
    "To efficiently implement the collaborative filtering cost function using matrix operations in TensorFlow, we organize all learning parameters and ratings into matrix form.\n",
    "\n",
    "### Notation\n",
    "\n",
    "| Notation | Description | Dimension |\n",
    "| :--- | :--- | :--- |\n",
    "| $n_m$ | Number of movies/items ||\n",
    "| $n_u$ | Number of users | |\n",
    "| $n$ | Number of learned features ||\n",
    "| $y^{(i,j)}$ | Rating given by user $j$ on movie $i$ | Scalar |\n",
    "| $r^{(i,j)}$ | Binary indicator: 1 if rated, 0 otherwise | Scalar |\n",
    "| $\\mathbf{x}^{(i)}$ | Feature vector for movie $i$ | $n \\times 1$ |\n",
    "| $\\mathbf{w}^{(j)}$ | Parameter vector for user $j$ | $n \\times 1$|\n",
    "| $b^{(j)}$ | Bias parameter for user $j$ | Scalar |\n",
    "| $\\mathbf{X}$ | Matrix of all item feature vectors | $n_m \\times n$ | Rows are $(\\mathbf{x}^{(i)})^T$ |\n",
    "| $\\mathbf{W}$ | Matrix of all user parameter vectors | $n_u \\times n$ | Rows are $(\\mathbf{w}^{(j)})^T$ |\n",
    "| $\\mathbf{b}$ | Vector of all user bias parameters | $1 \\times n_u$ | Rows are $b^{(j)}$ |\n",
    "| $\\mathbf{Y}$ | Matrix of user ratings (normalized) | $n_m \\times n_u$ | Elements are $y^{(i,j)}$ |\n",
    "| $\\mathbf{R}$ | Binary indicator matrix | $n_m \\times n_u$ | Elements are $r^{(i,j)}$ |\n",
    "\n",
    "### Matrix Definitions\n",
    "Here is how learning parameters would look like in matrix form:\n",
    "\n",
    "$$\n",
    "\\mathbf{X} = \n",
    "\\begin{bmatrix}\n",
    "--- (\\mathbf{x}^{(0)})^T --- \\\\\n",
    "--- (\\mathbf{x}^{(1)})^T --- \\\\\n",
    "\\vdots \\\\\n",
    "--- (\\mathbf{x}^{(n_m-1)})^T --- \\\\\n",
    "\\end{bmatrix} , \\quad\n",
    "\\mathbf{W} = \n",
    "\\begin{bmatrix}\n",
    "--- (\\mathbf{w}^{(0)})^T --- \\\\\n",
    "--- (\\mathbf{w}^{(1)})^T --- \\\\\n",
    "\\vdots \\\\\n",
    "--- (\\mathbf{w}^{(n_u-1)})^T --- \\\\\n",
    "\\end{bmatrix},\\quad\n",
    "\\mathbf{ b} = \n",
    "\\begin{bmatrix}\n",
    "b^{(0)}  \\\\\n",
    "b^{(1)} \\\\\n",
    "\\vdots \\\\\n",
    "b^{(n_u-1)} \\\\\n",
    "\\end{bmatrix}^T\n",
    "$$\n",
    "\n",
    "### Vectorized Cost Function ($J$)\n",
    "\n",
    "The vectorized collaborative filtering cost function includes the squared error between the predicted rating and the actual rating, along with regularization terms for the feature matrix $\\mathbf{X}$ and the parameter matrix $\\mathbf{W}$.\n",
    "\n",
    "$$\n",
    "J(\\mathbf{X}, \\mathbf{W}, \\mathbf{b}) = \\frac{1}{2} \\sum_{(i,j): r^{(i,j)}=1} \\left( (\\mathbf{w}^{(j)} \\cdot \\mathbf{x}^{(i)} + b^{(j)}) - y^{(i, j)} \\right)^2 + \\frac{\\lambda}{2} \\sum_{i=1}^{n_m} \\sum_{k=1}^{n} (x_k^{(i)})^2 + \\frac{\\lambda}{2} \\sum_{j=1}^{n_u} \\sum_{k=1}^{n} (w_k^{(j)})^2\n",
    "$$\n",
    "\n",
    "### Python Implementation with TensorFlow\n",
    "\n",
    "#### 1\\. Cost Function Definition\n",
    "\n",
    "The prediction matrix is calculated using the dot product of the feature matrix $\\mathbf{X}$ and the transpose of the parameter matrix $\\mathbf{W}$ (plus the bias vector $\\mathbf{b}$).\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "\n",
    "def cofi_cost_func_v(X, W, b, Y, R, lambda_):\n",
    "    \"\"\"\n",
    "    Returns the vectorized cost for Collaborative Filtering.\n",
    "    Args:\n",
    "      X (tf.Variable (num_movies,num_features)): Matrix of item features\n",
    "      W (tf.Variable (num_users,num_features)) : Matrix of user parameters\n",
    "      b (tf.Variable (1, num_users))            : Vector of user bias parameters\n",
    "      Y (ndarray (num_movies,num_users)    : Matrix of user ratings\n",
    "      R (ndarray (num_movies,num_users)    : Binary indicator matrix (1 if rated)\n",
    "      lambda_ (float): Regularization parameter\n",
    "    Returns:\n",
    "      J (float) : Cost\n",
    "    \"\"\"\n",
    "    # Prediction matrix (tf.linalg.matmul(X, tf.transpose(W)) + b) \n",
    "    # masked by R (tf.transpose(W) is used because W is (num_users, num_features))\n",
    "    error_matrix = (tf.linalg.matmul(X, tf.transpose(W)) + b - Y) * R\n",
    "    \n",
    "    # Squared Error Term\n",
    "    squared_error = 0.5 * tf.reduce_sum(error_matrix**2)\n",
    "    \n",
    "    # Regularization Term\n",
    "    regularization = (lambda_ / 2) * (tf.reduce_sum(X**2) + tf.reduce_sum(W**2))\n",
    "    \n",
    "    J = squared_error + regularization\n",
    "    return J\n",
    "```\n",
    "\n",
    "#### 2\\. Optimization using GradientTape (Auto Diff)\n",
    "\n",
    "TensorFlow's `tf.GradientTape` is used to automatically compute the gradients (partial derivatives) of the cost function with respect to the trainable parameters ($\\mathbf{X}$, $\\mathbf{W}$, and $\\mathbf{b}$).\n",
    "\n",
    "```python\n",
    "# Assuming X, W, and b are initialized as tf.Variables and optimizer is defined\n",
    "iterations = 200\n",
    "lambda_ = 1\n",
    "\n",
    "for iter in range(iterations):\n",
    "    # 1. Record the forward pass computation of the cost\n",
    "    with tf.GradientTape() as tape:\n",
    "        cost_value = cofi_cost_func_v(X, W, b, Ynorm, R, lambda_)\n",
    "\n",
    "    # 2. Compute the gradients using Automatic Differentiation\n",
    "    # Retrieves derivatives of cost_value with respect to the variables [X, W, b]\n",
    "    grads = tape.gradient( cost_value, [X, W, b] )\n",
    "\n",
    "    # 3. Apply the gradients using the defined optimizer (e.g., Adam)\n",
    "    optimizer.apply_gradients( zip(grads, [X, W, b]) )\n",
    "\n",
    "    # Log periodically\n",
    "    if iter % 20 == 0:\n",
    "        print(f\"Training loss at iteration {iter}: {cost_value:0.1f}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199eb199",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
